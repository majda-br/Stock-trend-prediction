{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yi61g2KeNIbP"
   },
   "source": [
    "# Project Models - CART, Random Forest, Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "id": "DtroNHr2NIbQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, confusion_matrix, roc_curve, auc\n",
    "from sklearn.utils import resample\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_error(y_pred, y_test):\n",
    "    return np.average(abs((y_pred - y_test) / y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OSR2(model, X_test, y_test, y_train):\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    SSE = np.sum((y_test - y_pred)**2)\n",
    "    SST = np.sum((y_test - np.mean(y_train))**2)\n",
    "                 \n",
    "    return (1 - SSE/SST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_predict, y_test):\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "    tn, fn, fp, tp = cm[0][0], cm[1][0], cm[0][1], cm[1][1]\n",
    "    FPR = fp / (fp + tn)\n",
    "    TPR = tp / (tp + fn)\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    PRE = 0\n",
    "    if (tp + fp != 0):\n",
    "        PRE = tp / (tp + fp)\n",
    "    return acc, TPR, FPR, PRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "id": "zRnchKRNNIbR",
    "outputId": "e595325e-32a4-438b-fa5d-aca871ac3d40"
   },
   "outputs": [],
   "source": [
    "ordered_data = pd.read_csv(\"../data.csv\")\n",
    "data = train_test_split(ordered_data)\n",
    "train_data, test_data = data[0], data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06746836296956246"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_data = train_test_split(ordered_data[['Unnamed: 0', 'Previous Week Tesla Stock Price', 'Tesla Stock Price']])\n",
    "base_data_train, base_data_test = base_data[0], base_data[1]\n",
    "\n",
    "y_train_base, x_train_base = base_data_train['Tesla Stock Price'], base_data_train[['Previous Week Tesla Stock Price', 'Unnamed: 0']]\n",
    "y_test_base, x_test_base = base_data_test['Tesla Stock Price'], base_data_test[['Previous Week Tesla Stock Price', 'Unnamed: 0']]\n",
    "\n",
    "ols_base = sm.OLS(y_train_base, x_train_base).fit()\n",
    "avg_error(ols_base.predict(x_test_base), y_test_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9AOg1RONIbS"
   },
   "source": [
    "## CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "id": "A6Q2kRfwNIbS",
    "outputId": "d120b563-98ad-47f7-91d8-ceda9059a55f"
   },
   "outputs": [],
   "source": [
    "y_train = train_data['Tesla Stock Price']\n",
    "X_train = pd.get_dummies(train_data.drop(['Tesla Stock Price', 'since', 'until'], axis=1))\n",
    "\n",
    "y_test = test_data['Tesla Stock Price']\n",
    "X_test = pd.get_dummies(test_data.drop(['Tesla Stock Price', 'since', 'until'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "id": "Goknz0ulNIbT",
    "outputId": "6e86fc44-189a-4019-e064-eec29d8a1835"
   },
   "outputs": [],
   "source": [
    "grid_values = {'ccp_alpha': np.linspace(0, 0.001, 51)}\n",
    "\n",
    "dtr = DecisionTreeRegressor(min_samples_leaf=5, min_samples_split=20, random_state=88)\n",
    "cv = KFold(n_splits=5,random_state=1,shuffle=True) \n",
    "dtr_cv = GridSearchCV(dtr, param_grid=grid_values, scoring='r2', cv=cv, verbose=0)\n",
    "dtr_cv.fit(X_train, y_train)\n",
    "test_pred_cart, train_pred_cart = dtr_cv.predict(X_test), dtr_cv.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "id": "I1haFOjINIbU",
    "outputId": "f13b9b7d-f4ab-46b2-a3e3-ca2e222fa723"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated R2: 0.95473\n",
      "OSR2: 0.95826\n",
      "Average Percent Error: 0.07925061561883433\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "print('Cross-validated R2:', round(dtr_cv.best_score_, 5))\n",
    "print('OSR2:', round(OSR2(dtr_cv, X_test, y_test, y_train), 5))\n",
    "print('Average Percent Error: ' + str(avg_error(dtr_cv.predict(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGoe1rZONIbU"
   },
   "source": [
    "## RANDOM FORESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "id": "ox5Kl5kBNIbV",
    "outputId": "cdc153aa-8e26-421c-91ae-c882e027cb1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] END max_features=1, min_samples_leaf=5, n_estimators=500, random_state=88; total time=   0.6s\n",
      "[CV] END max_features=1, min_samples_leaf=5, n_estimators=500, random_state=88; total time=   0.6s\n",
      "[CV] END max_features=1, min_samples_leaf=5, n_estimators=500, random_state=88; total time=   0.6s\n",
      "[CV] END max_features=1, min_samples_leaf=5, n_estimators=500, random_state=88; total time=   0.6s\n",
      "[CV] END max_features=1, min_samples_leaf=5, n_estimators=500, random_state=88; total time=   0.6s\n",
      "[CV] END max_features=2, min_samples_leaf=5, n_estimators=500, random_state=88; total time=   0.6s\n",
      "[CV] END max_features=2, min_samples_leaf=5, n_estimators=500, random_state=88; total time=   0.6s\n",
      "[CV] END max_features=2, min_samples_leaf=5, n_estimators=500, random_state=88; total time=   0.6s\n",
      "[CV] END max_features=2, min_samples_leaf=5, n_estimators=500, random_state=88; total time=   0.6s\n",
      "[CV] END max_features=2, min_samples_leaf=5, n_estimators=500, random_state=88; total time=   0.6s\n",
      "[CV] END max_features=3, min_samples_leaf=5, n_estimators=500, random_state=88; total time=   0.7s\n",
      "[CV] END max_features=3, min_samples_leaf=5, n_estimators=500, random_state=88; total time=   0.7s\n",
      "[CV] END max_features=3, min_samples_leaf=5, n_estimators=500, random_state=88; total time=   0.7s\n",
      "[CV] END max_features=3, min_samples_leaf=5, n_estimators=500, random_state=88; total time=   0.7s\n",
      "[CV] END max_features=3, min_samples_leaf=5, n_estimators=500, random_state=88; total time=   0.7s\n",
      "[CV] END max_features=4, min_samples_leaf=5, n_estimators=500, random_state=88; total time=   0.7s\n",
      "[CV] END max_features=4, min_samples_leaf=5, n_estimators=500, random_state=88; total time=   0.7s\n",
      "[CV] END max_features=4, min_samples_leaf=5, n_estimators=500, random_state=88; total time=   0.7s\n",
      "[CV] END max_features=4, min_samples_leaf=5, n_estimators=500, random_state=88; total time=   0.7s\n",
      "[CV] END max_features=4, min_samples_leaf=5, n_estimators=500, random_state=88; total time=   0.7s\n",
      "[CV] END max_features=5, min_samples_leaf=5, n_estimators=500, random_state=88; total time=   0.8s\n",
      "[CV] END max_features=5, min_samples_leaf=5, n_estimators=500, random_state=88; total time=   0.8s\n",
      "[CV] END max_features=5, min_samples_leaf=5, n_estimators=500, random_state=88; total time=   0.8s\n",
      "[CV] END max_features=5, min_samples_leaf=5, n_estimators=500, random_state=88; total time=   0.8s\n",
      "[CV] END max_features=5, min_samples_leaf=5, n_estimators=500, random_state=88; total time=   0.8s\n"
     ]
    }
   ],
   "source": [
    "grid_values = {'max_features': np.linspace(1,5,5, dtype='int32'),\n",
    "               'min_samples_leaf': [5],\n",
    "               'n_estimators': [500],\n",
    "               'random_state': [88]} \n",
    "\n",
    "rf2 = RandomForestRegressor() \n",
    "cv = KFold(n_splits=5,random_state=333,shuffle=True) \n",
    "rf_cv = GridSearchCV(rf2, param_grid=grid_values, scoring='r2', cv=cv,verbose=2)\n",
    "rf_cv.fit(X_train, y_train)\n",
    "test_pred_rf, train_pred_rf = rf_cv.predict(X_test), rf_cv.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "id": "u5WiB1_TNIbV",
    "outputId": "a607f880-2b7c-46eb-859d-fad514473517"
   },
   "outputs": [],
   "source": [
    "max_features = rf_cv.cv_results_['param_max_features'].data\n",
    "R2_scores = rf_cv.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "id": "BelKh4byNIbV",
    "outputId": "59037962-f7b7-45b5-8176-adb5af2593d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated R2: 0.98535\n",
      "OSR2: 0.97848\n",
      "Average Percent Error: 0.05705805720101074\n"
     ]
    }
   ],
   "source": [
    "print('Cross-validated R2:', round(rf_cv.best_score_, 5))\n",
    "print('OSR2:', round(OSR2(rf_cv, X_test, y_test, y_train), 5))\n",
    "print('Average Percent Error: ' + str(avg_error(rf_cv.predict(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4QRyHjU8NIbW"
   },
   "source": [
    "## GRADIENT BOOSTED TREES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = GradientBoostingRegressor(random_state=99)\n",
    "reg.fit(X_train, y_train)\n",
    "test_pred_reg, train_pred_reg = reg.predict(X_test), reg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "id": "b_8GeaMaNIba",
    "outputId": "7db3b71b-c705-4c57-9368-8d242dc74330"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OSR2: 0.99081\n",
      "Average Percent Error: 0.06193615009596899\n"
     ]
    }
   ],
   "source": [
    "print('OSR2:', round(OSR2(reg, X_test, y_test, y_train), 5))\n",
    "print('Average Percent Error: ' + str(avg_error(reg.predict(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "id": "-rm14ayINIba",
    "outputId": "32449141-076b-48fb-e8ec-2eefeefb3cb1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unnamed: 0</td>\n",
       "      <td>68.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S&amp;P 500 Variance</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ford Stock Price</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GM Stock Price</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Toyota Stock Price</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nissan Stock Price</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tesla Wikipedia Page Views</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sentiment</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Previous Week Tesla Stock Price</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Feature  Importance score\n",
       "0                       Unnamed: 0              68.3\n",
       "1                 S&P 500 Variance               0.0\n",
       "2                 Ford Stock Price               0.1\n",
       "3                   GM Stock Price               0.0\n",
       "4               Toyota Stock Price               0.2\n",
       "5               Nissan Stock Price               3.8\n",
       "6       Tesla Wikipedia Page Views               0.5\n",
       "7                        Sentiment               0.0\n",
       "8  Previous Week Tesla Stock Price              27.0"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Feature' : X_train.columns, \n",
    "              'Importance score': 100*reg.feature_importances_}).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rSFd4X1NIbb"
   },
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "id": "qdrmVAvPNIbb",
    "outputId": "f432dc54-602f-46ff-e7b1-e626bcf08c7e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6d441_ th {\n",
       "  font-size: 10pt;\n",
       "}\n",
       "#T_6d441_row0_col0, #T_6d441_row0_col1, #T_6d441_row0_col2, #T_6d441_row1_col0, #T_6d441_row1_col1, #T_6d441_row1_col2, #T_6d441_row2_col0, #T_6d441_row2_col1, #T_6d441_row2_col2 {\n",
       "  font-size: 12pt;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6d441_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Decision Tree Regressor</th>\n",
       "      <th class=\"col_heading level0 col1\" >Random Forest</th>\n",
       "      <th class=\"col_heading level0 col2\" >Gradient Boosted Trees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6d441_level0_row0\" class=\"row_heading level0 row0\" >OSR2</th>\n",
       "      <td id=\"T_6d441_row0_col0\" class=\"data row0 col0\" >0.958</td>\n",
       "      <td id=\"T_6d441_row0_col1\" class=\"data row0 col1\" >0.978</td>\n",
       "      <td id=\"T_6d441_row0_col2\" class=\"data row0 col2\" >0.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6d441_level0_row1\" class=\"row_heading level0 row1\" >Out-of-sample MSE</th>\n",
       "      <td id=\"T_6d441_row1_col0\" class=\"data row1 col0\" >140.2876</td>\n",
       "      <td id=\"T_6d441_row1_col1\" class=\"data row1 col1\" >72.3227</td>\n",
       "      <td id=\"T_6d441_row1_col2\" class=\"data row1 col2\" >30.8958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6d441_level0_row2\" class=\"row_heading level0 row2\" >Out-of-sample MAE</th>\n",
       "      <td id=\"T_6d441_row2_col0\" class=\"data row2 col0\" >3.517</td>\n",
       "      <td id=\"T_6d441_row2_col1\" class=\"data row2 col1\" >2.494</td>\n",
       "      <td id=\"T_6d441_row2_col2\" class=\"data row2 col2\" >1.788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe432026760>"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_data = {'Decision Tree Regressor': ['{:.3f}'.format(OSR2(dtr_cv, X_test, y_test, y_train)),\n",
    "                                               '{:.4f}'.format(mean_squared_error(y_test, dtr_cv.predict(X_test))),\n",
    "                                               '{:.3f}'.format(mean_absolute_error(y_test, dtr_cv.predict(X_test)))],\n",
    "                   'Random Forest': ['{:.3f}'.format(OSR2(rf_cv, X_test, y_test, y_train)),\n",
    "                                     '{:.4f}'.format(mean_squared_error(y_test, rf_cv.predict(X_test))),\n",
    "                                     '{:.3f}'.format(mean_absolute_error(y_test, rf_cv.predict(X_test)))], \n",
    "                   'Gradient Boosted Trees': ['{:.3f}'.format(OSR2(reg, X_test, y_test, y_train)),\n",
    "                                              '{:.4f}'.format(mean_squared_error(y_test, reg.predict(X_test))),\n",
    "                                              '{:.3f}'.format(mean_absolute_error(y_test, reg.predict(X_test)))]}\n",
    "\n",
    "comparison_table = pd.DataFrame(data=comparison_data, index=['OSR2', 'Out-of-sample MSE', 'Out-of-sample MAE'])\n",
    "comparison_table.style.set_properties(**{'font-size': '12pt',}).set_table_styles([{'selector': 'th', 'props': [('font-size', '10pt')]}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Model Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data['Tesla Stock Price']\n",
    "train = pd.DataFrame({'Tesla_Stock_Price': y_train, 'val_pred_cart': train_pred_cart, 'val_pred_rf': train_pred_rf, 'val_pred_reg': train_pred_reg})\n",
    "\n",
    "y_test = test_data['Tesla Stock Price']\n",
    "test = pd.DataFrame({'Tesla_Stock_Price': y_test, 'val_pred_cart': test_pred_cart, 'val_pred_rf': test_pred_rf, 'val_pred_reg': test_pred_reg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = smf.ols(formula='Tesla_Stock_Price ~ val_pred_cart+val_pred_reg+val_pred_rf -1', data=train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Percent Error: 0.06261219111933379\n"
     ]
    }
   ],
   "source": [
    "print('Average Percent Error: ' + str(avg_error(ensemble_model.predict(test), y_test)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
